---
title: "Homework2"
author: "Ayeshra Acharya"
date: "9/26/2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```
Read the Trashwheel data 

## Problem 1
```{r}
trashwheel_df = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
            sheet = "Mr. Trash Wheel",
            range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read Precipitation data

```{r}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
            sheet = "2018 Precipitation", 
            skip = 1
  ) %>%
 janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
            sheet = "2018 Precipitation", 
            skip = 1
  ) %>%
 janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now, combine annual precipitation. 
```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018,precip_2017)

left_join(precip_df, month_df, by = "month")
``` 

This dataset contains information from the Mr. Trashwheel trash collector located in Baltimore, MD. As trash enters the inner harbor, the trashwheel collects that trash and then stores it in a dumpster. The dataset contains information on year, month, and trash collected, including some specific kinds of trash. There are a total of 344 rows in our final dataset. Additional data sheets include month precipitation data. 

##Problem 2

Read in the NYC transit data file, clean the data, retain specific variables and convert the variable entry from character to logic. 
```{r}
nyc_transit = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(
     entry = as.character(entry),
     entry = replace(entry,entry == "YES", "TRUE"),
     entry = replace(entry,entry == "NO", "FALSE"),
     entry = as.logical(entry)
)
```

```{r}
names(nyc_transit)
```
```{r}
nrow(nyc_transit)
ncol(nyc_transit)
```
The NYC Transit dataset contains the variables: station name, line, entry division, routes served, ADA compliance, and several other variables pertaining to longitudinal/latitude data, entrance location and routes. My data cleaning steps so far have included 1) reading the data 2) cleaning the data 3) selecting desired variables and 4) changing the variable "entry" from character to logical. The dimensions of the 
dataset is 1868 rows * 19 columns. The data is not tidy since there is a different column for each route number. 

Making the data tidy 
```{r}
nyc_transit_tidy = 
  nyc_transit %>%
  mutate(
    route8 = as.character (route8),
    route9 = as.character (route9),
    route10 = as.character (route10),
    route11 = as.character(route11)
  ) %>%
  pivot_longer(
    route1 :route11,
    names_to = "route_num",
    values_to = "route_name"
  )
```


Finding the distinct stations 
```{r}
total_stations = select(nyc_transit,line,station_name,ada) %>%
  distinct()
nrow(total_stations)
```
There are 465 total distinct stations. 

ADA compliant stations 
```{r}
ada_compliant = filter(total_stations, ada=="TRUE")
nrow(ada_compliant)
```
There are a total of 84 stations that are ADA compliant. 

Proportion of station entrances/exits without vending that allow entrance. 
```{r}
nrow(filter(nyc_transit, vending=="NO",entry=="TRUE"))/nrow(filter(nyc_transit,vending=="NO"))
```
37.70% of station entrances/exits without vending allow entrances. 

Reformat data so that route number and route name are distinct variables
```{r}
formatted_nyc_transit = 
  nyc_transit %>%
  gather(key = "route_name", value = "route_number",route1:route11) %>%
  filter(route_number=="A")
```

Finding the distinct stations that serve the A train 
```{r}
A_train = distinct(formatted_nyc_transit, line, station_name,.keep_all = TRUE)
nrow(A_train)
```
There are a total of 60 distinct stations that serve the A train. 

ADA complaince in A train
```{r}
nrow(filter(A_train,ada=="TRUE"))
```
Of the 60 distinct stations that serve the A train, 17 are ADA compliant. 

##Problem 3

Read and clean the data. First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day. create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
```{r}
pols_data=
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon,into = c("year","month","day")) %>%
  mutate(
    month = month.abb[as.factor(month)],
    year = as.factor(year)
  )%>%
  mutate(
    president = case_when(
      prez_dem == 0 ~ "gop",
      prez_dem == 1 ~ "dem")) %>%
  relocate(year, month) %>%
  select(-day, -prez_gop,-prez_dem)
```

Replace month number as month name. 
```{r}
month_dataset= 
  tibble(
    month = 1:12,
    month_name = month.name
  )
```

Clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns. Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.
```{r}
snp_data =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
    separate(date,into = c("day","month","year")) %>%
  mutate(
    month = month.abb[as.factor(month)],
    year = as.factor(year)
  )%>%
  relocate(year, month)

unemployment_data = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  mutate(
    Year = as.factor(Year)
  ) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemp"
    ) %>%
 rename(
   year = Year
 ) %>% mutate (
   month = month.abb[as.factor(month)]
 )
```
Join the datasets by merging snp into pols
```{r}
snp_pols = 
  left_join(pols_data,snp_data, by = c("year","month"))
```
Merging unemployment into the result
```{r}
snp_pols_unemploy = 
  left_join(snp_pols, unemployment_data, by = c("year","month"))
```
Description of datasets: 

The "pols-month" data set includes information on the number of politicians including the president, governors, senators  in each party affiliation from the year 1947 to 2015.`pols_data` contains `r nrow(pols_data)` observations and `r ncol(pols_data)` variables related to the number of national politicians (the president, governors, senators, and representatives) who are democratic or republican. 

The `snp` dataset contains `r nrow(snp_data)` observations and `r ncol(snp_data)` variables relating to the Standard & Poor's stock market index, which represents the stock market's performance overall. 

The "'unemployment" dataset contains `r nrow(unemployment_data)` observations and `r ncol(unemployment_data)` variables, which provides the percentage of unemployment in a particular month from the year 1948 to 2015. 
Then, using these datasets, a combined dataset `snp_pols_unemploy` was created, containing `r nrow(snp_pols_unemploy)` observations and `r ncol(snp_pols_unemploy)` variables. Some of the  key variables in the 'snp_pols_unemploy' include: "president", "close" and "unemp". These variables are important because they sum up the other datasets that we combined. 
